; Central configuration file used for building docker images for the various
; services as well as for services run in docker containers
;

; Rancher section 
[RANCHER]

; Id of the environment we are using to bring up containers
env_id = <RANCHER_ENVIRONMENT>

; Base url of rancher's restful API
rest_base_url = <PROTOCOL>://<RANCHER_HOST>:<PORT>/v1/projects/%(env_id)s

; Base url of rancher's restful API v2
rest_base_url_v2 = <PROTOCOL>://<RANCHER_HOST>:<PORT>/v2-beta/projects/%(env_id)s

; Access key for authentication with rancher API
access_key = <RANCHER_ACCESS_KEY>

; Secret key for rancher for authentication with rancher api
secret_key = <RANCHER_SECRET_KEY>

; Max number of resources returned by rancher in one fell swoop in a get request.
; See http://docs.rancher.com/rancher/v1.3/en/api/v2-beta/ for details.
; IMPORTANT NOTE: If we ever have more than 100 containers to query for status
; we need to adjust the scripts to work with pagination!
pagination_limit = 500


; Section for monitor script that fetches status of rancher notebook stacks
[NOTEBOOK_MONITOR]

; Directory within directory pointed to by env var JHUB_SETUP_DIR with scripts 
; and configuration for the notebook server monitor
base_dir = services/nb_mon

; File to store the status of each notebook server (on host)
host_status_file = /var/log/nbs_status.txt

; File to store log/error messages of the notebook monitor script (on host)
host_log_file = /var/log/nbs_monitor.log

; Time in seconds to wait between status queries
wait_interval_seconds = 1

; Notebook monitor docker image 
docker_image = registry.dev.container.auckland.ac.nz:5000/mfel395/jhub_nbs_mon:1.2

; Name of docker container
docker_container_name = nb_mon

; Section for load balancer of jupyterhub instances (HAProxy)
[LOAD_BALANCER]

; Directory within directory pointed to by env var JHUB_SETUP_DIR with scripts 
; and configuration for the hub load-balancer (haproxy)
base_dir = services/haproxy

; Port of UI interface of jupyterhub
ui_port = 80

; Port of API interface of jupyterhub
api_port = 8080

; Directory where files are stored that map users to jupyterhub instances
server_mappings_dir=%(base_dir)s/server_mappings

; Directory where configuration templates are stored. These are used to create
; the HAProxy configuration file
template_dir=%(base_dir)s/templates

; Path to HAProxy configuration file 
config_file=%(base_dir)s/etc/haproxy.cfg

; HAProxy docker image
docker_image = registry.dev.container.auckland.ac.nz:5000/mfel395/haproxy:1.7

; Name of docker container
docker_container_name = haproxy


; Section for jupyter hub
[JUPYTERHUB]

; Directory within directory pointed to by env var JHUB_SETUP_DIR with scripts
; and configuration for jupyterhub
base_dir = services/jhub

; Directory that contains the configuration templates
template_dir = %(base_dir)s/template

; Base directory for the hub directories (one directory for each hub)
live_hubs_base_dir = %(base_dir)s/live_hubs

; IP of the machine where the docker jupyterhub instances are running
hub_ip = <IP>

; Authentication token for jupyterhub API
api_token = <JUPYTERHUB_API_TOKEN>

; Label for containers
hub_label = CER_DEV

; Number of jupyterhub instances to spawn
num_hubs = 50

; Start port for jupyterhub UI. If we have 5 hubs they will listen on
; ports 10000-10004
port_range_start = 10000

; Start port for jupyterhub proxy api.
; Not used, but must be unique for each hub instance.
; If we have 5 hubs they will listen on ports 10100-10104
proxy_api_port_range_start = 10100

; Start port for jupyterhub API.
; If we have 5 hubs, they will listen on ports 10200-10204
api_port_range_start = 10200

; Docker image used by jupyterhub servers
docker_image = registry.dev.container.auckland.ac.nz:5000/mfel395/jupyterhub:0.7.2

; Docker image used by jupyterhub servers
docker_container_base_name = hub

; Docker image used by jupyterhub notebook servers
notebook_server_docker_image = registry.dev.container.auckland.ac.nz:5000/mfel395/jhub-common-notebook:1.0

; Folder on cows, possible an NFS share, where all the user directories are located
cow_user_folder_dir = /mnt/docker_cer

; Section for user scripts to manage users
[SCRIPTS]

; Directory within directory pointed to by env var JHUB_SETUP_DIR with scripts 
; and configuration for user management scripts
base_dir = scripts

